{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64d0cc2-4d49-46ec-a66b-9dfd42259b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from groq import Groq\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965afa56-3e28-40c7-b130-bc2795a017bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b05efb-8da1-4d30-86dd-ae1745043730",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/vietnamese_rag/documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b81f355b-b108-4b31-b6f4-38f93342f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 6089/6089 [05:36<00:00, 18.10it/s]\n"
     ]
    }
   ],
   "source": [
    "context_vector_list = []\n",
    "for doc in tqdm(documents):\n",
    "    temp_dict = {}\n",
    "    context = doc['context']\n",
    "    temp_dict['context_vector'] = model.encode(context)\n",
    "    context_vector_list.append(temp_dict)\n",
    "with open('../data/vietnamese_rag/context_vector_pickle/context_vector.pkl', 'wb') as file:\n",
    "    pickle.dump(context_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63df8320-4f0a-48fa-ab56-66009fa59753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 6089/6089 [02:20<00:00, 43.40it/s]\n"
     ]
    }
   ],
   "source": [
    "question_vector_list = []\n",
    "for doc in tqdm(documents):\n",
    "    temp_dict = {}\n",
    "    question = doc['question']\n",
    "    temp_dict['question_vector'] = model.encode(question)\n",
    "    question_vector_list.append(temp_dict)\n",
    "with open('../data/vietnamese_rag/question_vector_pickle/question_vector.pkl', 'wb') as file:\n",
    "    pickle.dump(question_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8820e58e-7917-483a-a07f-a9cdc1556c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████| 6089/6089 [04:03<00:00, 25.04it/s]\n"
     ]
    }
   ],
   "source": [
    "answer_vector_list = []\n",
    "for doc in tqdm(documents):\n",
    "    temp_dict = {}\n",
    "    answer = doc['answer']\n",
    "    temp_dict['question_vector'] = model.encode(answer)\n",
    "    answer_vector_list.append(temp_dict)\n",
    "with open('../data/vietnamese_rag/answer_vector_pickle/answer_vector.pkl', 'wb') as file:\n",
    "    pickle.dump(answer_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf7699-6059-4416-a053-d62863ee9688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                             | 24/6089 [00:01<05:20, 18.92it/s]"
     ]
    }
   ],
   "source": [
    "qta_vector_list = []\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    question = doc['question']\n",
    "    context = doc['context']\n",
    "    answer = doc['answer']\n",
    "    qta = question + ' ' + context + \" \" + answer\n",
    "    temp_dict = {}\n",
    "    temp_dict['question_context_answer_vector'] = model.encode(qta)\n",
    "    qta_vector_list.append(temp_dict)\n",
    "with open('../data/vietnamese_rag/question_context_answer_vector_pickle/question_context_answer_vector.pkl', 'wb') as file:\n",
    "    pickle.dump(qta_vector_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f8294-343a-4be8-bf99-123c312c997f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
